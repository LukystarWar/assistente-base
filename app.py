import streamlit as st
import os
from dotenv import load_dotenv
from openai import OpenAI

# Carrega variÃ¡veis de ambiente
load_dotenv()

# ConfiguraÃ§Ã£o da API Groq
client = OpenAI(
    api_key=os.getenv('GROQ_API_KEY'),
    base_url="https://api.groq.com/openai/v1"
)

def load_system_prompt():
    try:
        with open('prompt.txt', 'r', encoding='utf-8') as file:
            return file.read().strip()
    except FileNotFoundError:
        return "VocÃª Ã© um assistente prestativo e direto."

def get_ai_response(messages):
    try:
        response = client.chat.completions.create(
            model="llama3-70b-8192",
            messages=messages
        )
        return response.choices[0].message.content
    except Exception as e:
        return f"Erro ao comunicar com a API: {str(e)}"

# ConfiguraÃ§Ã£o da pÃ¡gina
st.set_page_config(
    page_title="Assistante IA", 
    page_icon="ğŸ¤–",
    layout="centered"
)

st.title("ğŸ¬ Framey IA")
st.caption("Converse com o Assistente usando modelos avanÃ§ados de IA")

# InicializaÃ§Ã£o do histÃ³rico na sessÃ£o
if "messages" not in st.session_state:
    st.session_state.messages = [
        {"role": "system", "content": load_system_prompt()}
    ]

# Exibe o histÃ³rico de mensagens usando st.chat_message
for message in st.session_state.messages[1:]:  # Pula a mensagem do sistema
    if message["role"] == "user":
        with st.chat_message("user"):
            st.markdown(message["content"])
    else:
        with st.chat_message("assistant", avatar="ğŸ¬"):
            st.markdown(message["content"])

# Campo de entrada do usuÃ¡rio usando st.chat_input
if prompt := st.chat_input("Digite sua pergunta aqui..."):
    # Adiciona e exibe mensagem do usuÃ¡rio
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)
    
    # ObtÃ©m e exibe resposta da IA
    with st.chat_message("assistant", avatar="ğŸ¬"):
        with st.spinner("Pensando..."):
            response = get_ai_response(st.session_state.messages)
        st.markdown(response)
        
        # Adiciona resposta ao histÃ³rico
        st.session_state.messages.append({"role": "assistant", "content": response})

# BotÃ£o para limpar histÃ³rico
if st.sidebar.button("ğŸ—‘ï¸ Limpar Conversa"):
    st.session_state.messages = [
        {"role": "system", "content": load_system_prompt()}
    ]
    st.rerun()